"""init

Revision ID: ee276b14f2da
Revises: 
Create Date: 2025-10-24 15:50:22.399413

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = 'ee276b14f2da'
down_revision: Union[str, None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('areas',
    sa.Column('id', sa.BIGINT(), autoincrement=True, nullable=False),
    sa.Column('name', sa.String(length=200), nullable=False),
    sa.Column('code', sa.String(length=100), nullable=False),
    sa.Column('area_type', postgresql.ENUM('BEDROOM', 'FAMILY', 'OFFICE', 'MIXED', 'OTHER', name='area_type'), nullable=True),
    sa.Column('center_lon', sa.Float(), nullable=True),
    sa.Column('center_lat', sa.Float(), nullable=True),
    sa.Column('bounds_geojson', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.Column('metadata', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('code')
    )
    op.create_index(op.f('ix_areas_name'), 'areas', ['name'], unique=False)
    op.create_table('indicator_definitions',
    sa.Column('id', sa.BIGINT(), autoincrement=True, nullable=False),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('classifications',
    sa.Column('id', sa.BIGINT(), autoincrement=True, nullable=False),
    sa.Column('area_id', sa.BIGINT(), nullable=False),
    sa.Column('effective_from', sa.TIMESTAMP(timezone=True), nullable=False),
    sa.Column('effective_to', sa.TIMESTAMP(timezone=True), nullable=True),
    sa.Column('area_type', postgresql.ENUM('BEDROOM', 'FAMILY', 'OFFICE', 'MIXED', 'OTHER', name='area_type'), nullable=False),
    sa.Column('confidence', sa.Numeric(precision=3, scale=2), nullable=False),
    sa.Column('rationale', sa.Text(), nullable=True),
    sa.CheckConstraint('confidence >= 0 AND confidence <= 1', name='ck_class_confidence_range'),
    sa.ForeignKeyConstraint(['area_id'], ['areas.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('district_aggregates',
    sa.Column('id', sa.BIGINT(), autoincrement=True, nullable=False),
    sa.Column('area_id', sa.BIGINT(), nullable=False),
    sa.Column('period_start', sa.TIMESTAMP(timezone=True), nullable=False),
    sa.Column('period_minutes', sa.Integer(), nullable=False),
    sa.Column('daypart', sa.String(length=32), nullable=True),
    sa.Column('device_count_avg', sa.Float(), nullable=True),
    sa.Column('device_count_peak', sa.Float(), nullable=True),
    sa.Column('data_transfer_bytes_sum', sa.Float(), nullable=True),
    sa.Column('data_transfer_bytes_avg', sa.Float(), nullable=True),
    sa.Column('presence_count_avg', sa.Float(), nullable=True),
    sa.Column('green_presence_ratio_avg', sa.Float(), nullable=True),
    sa.Column('digital_noise_score_avg', sa.Float(), nullable=True),
    sa.Column('social_accessibility_score_avg', sa.Float(), nullable=True),
    sa.Column('life_balance_score_avg', sa.Float(), nullable=True),
    sa.Column('safety_reports_count_sum', sa.Float(), nullable=True),
    sa.Column('observations', sa.Integer(), nullable=True),
    sa.Column('computed_at', sa.TIMESTAMP(timezone=True), nullable=False),
    sa.Column('metadata', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.ForeignKeyConstraint(['area_id'], ['areas.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('area_id', 'period_start', 'period_minutes', 'daypart', name='uq_district_agg')
    )
    op.create_index('idx_dagg_area_period', 'district_aggregates', ['area_id', 'period_start'], unique=False)
    op.create_index('idx_dagg_daypart', 'district_aggregates', ['daypart'], unique=False)
    op.create_table('metric_facts',
    sa.Column('id', sa.BIGINT(), autoincrement=True, nullable=False),
    sa.Column('area_id', sa.BIGINT(), nullable=False),
    sa.Column('indicator_id', sa.BIGINT(), nullable=False),
    sa.Column('ts', sa.TIMESTAMP(timezone=True), nullable=False),
    sa.Column('bucket_minutes', sa.Integer(), nullable=False),
    sa.Column('daypart', postgresql.ENUM('MORNING', 'NOON', 'EVENING', 'NIGHT', name='daypart'), nullable=True),
    sa.Column('value', sa.Float(), nullable=False),
    sa.Column('sample_size', sa.Integer(), nullable=True),
    sa.Column('metadata', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
    sa.ForeignKeyConstraint(['area_id'], ['areas.id'], ondelete='CASCADE'),
    sa.ForeignKeyConstraint(['indicator_id'], ['indicator_definitions.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('area_id', 'indicator_id', 'ts', 'bucket_minutes', name='uq_metric_key')
    )
    op.create_index('idx_metric_area_indicator_ts', 'metric_facts', ['area_id', 'indicator_id', 'ts'], unique=False)
    op.create_index('idx_metric_daypart', 'metric_facts', ['daypart'], unique=False)
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index('idx_metric_daypart', table_name='metric_facts')
    op.drop_index('idx_metric_area_indicator_ts', table_name='metric_facts')
    op.drop_table('metric_facts')
    op.drop_index('idx_dagg_daypart', table_name='district_aggregates')
    op.drop_index('idx_dagg_area_period', table_name='district_aggregates')
    op.drop_table('district_aggregates')
    op.drop_table('classifications')
    op.drop_table('indicator_definitions')
    op.drop_index(op.f('ix_areas_name'), table_name='areas')
    op.drop_table('areas')
    # ### end Alembic commands ###
